{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import os\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# folder = 'Telegraaf'\n",
    "# document_top = 1\n",
    "\n",
    "# for infile in glob.glob( os.path.join(folder, '*.xml'))[:document_top]:\n",
    "#         # get the html text\n",
    "#         fileIndex = os.path.basename(infile).replace('.xml','')\n",
    "#         print(\"Current file is {}\".format(fileIndex))\n",
    "\n",
    "#         print(\"\\tReading...\")\n",
    "#         # Open the file and read it\n",
    "#         with open(infile, 'r', encoding='utf-8') as f:\n",
    "#             soup = BeautifulSoup(f.read(), \"html.parser\")\n",
    "            \n",
    "#             print(\"\\tFormatting...\")\n",
    "#             all_roots = soup.findAll(\"pm:root\".split())\n",
    "            \n",
    "#             print(\"\\tSaving...\")\n",
    "#             for root in all_roots:\n",
    "#                 print(root.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch()\n",
    "\n",
    "# ignore 400 cause by IndexAlreadyExistsException when creating an index\n",
    "es.indices.create(index='test-index', ignore=400)\n",
    "\n",
    "# ignore 404 and 400\n",
    "es.indices.delete(index='test-index', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import gzip\n",
    "\n",
    "folder = 'Telegraaf'\n",
    "\n",
    "total_amount_records = 0\n",
    "for infile in glob.glob( os.path.join(folder, '*.xml.gz')):\n",
    "        # get the html text\n",
    "        fileIndex = os.path.basename(infile).replace('.xml.gz','')\n",
    "        print(\"\")\n",
    "        print(\"Current file is {}\".format(fileIndex))\n",
    "\n",
    "        print(\"\\tOpening...\")\n",
    "        # Open the file and read it\n",
    "        with gzip.open(infile, 'r') as f:\n",
    "            soup = BeautifulSoup(f.read(), \"html.parser\")\n",
    "            \n",
    "            print(\"\\tFormatting...\")\n",
    "            all_roots = soup.findAll(\"pm:root\".split())\n",
    "            total_amount_roots = len(all_roots)\n",
    "            current_index_root = 0\n",
    "            \n",
    "            print(\"\\tReading and saving...\")\n",
    "            for root in all_roots:\n",
    "                \n",
    "                _date = root.find(\"dc:date\").text\n",
    "                subject = root.find(\"dc:subject\").text\n",
    "                identifier = root.find(\"dc:identifier\").text\n",
    "#                 link = root.find(\"pm:link\").text # de source is dan http://kranten.kb.nl/view/article/id/ + de link? <KLOPT>\n",
    "#                 source_denk_ik = \"http://kranten.kb.nl/view/article/id/{}\".format(identifier)\n",
    "                title = root.find(\"title\").text\n",
    "                text = root.find(\"text\").text\n",
    "                \n",
    "#                 total_p = \"\"\n",
    "#                 for p in root.find(\"text\").findAll(\"p\"):\n",
    "#                     total_p = \"{}\\n\\t{}\".format(total_p,p.text)\n",
    "                    \n",
    "#                 print('\\ndate:{},  subject:{}  \\nidentifier: {}, link: {}, source: {} \\ntitle: {}, text: {} \\ntotal_p: {}\\n\\n'.format(\n",
    "#                     _date,subject,identifier,link,source_denk_ik,title,text,total_p))\n",
    "                \n",
    "                \n",
    "                \n",
    "                es.index(index='krant',doc_type=subject, id=identifier, body={\n",
    "                    'title': title,\n",
    "                    'text': text,\n",
    "                    'date': _date\n",
    "                })\n",
    "                \n",
    "\n",
    "                \n",
    "                current_index_root += 1\n",
    "                sys.stdout.write('\\r' + \"\\t\\t{}/{}\".format(current_index_root,total_amount_roots))\n",
    "                sys.stdout.flush()\n",
    "        total_amount_records += total_amount_roots\n",
    "        \n",
    "print(\"Everything is done, a total of {} records are saved\".format(total_amount_records))\n",
    "                \n",
    "#  1969 is af, 1970 was bezig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "es.search(doc_type='artikel', q='PRIVÃ‰ WILLEKE KRIJGT HOOFDROL BIJ VERONIOUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Env35]",
   "language": "python",
   "name": "conda-env-Env35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
